{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ“ Theory Primer: Quantum Kernel Methods\n",
        "\n",
        "**A Gentle Introduction for Researchers New to Quantum Machine Learning**\n",
        "\n",
        "---\n",
        "\n",
        "This notebook provides the theoretical background needed to understand the experiments in this repository. We'll cover:\n",
        "\n",
        "1. What are kernel methods?\n",
        "2. Classical vs Quantum kernels\n",
        "3. Feature maps and Hilbert spaces\n",
        "4. Why eigenvalues measure expressivity\n",
        "\n",
        "No quantum computing experience required! ðŸš€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. What Are Kernel Methods?\n",
        "\n",
        "### The Problem\n",
        "Many machine learning problems are **not linearly separable**. For example, consider points arranged in concentric circles - no straight line can separate them.\n",
        "\n",
        "### The Solution: Feature Maps\n",
        "A **feature map** $\\Phi$ transforms data into a higher-dimensional space where it *becomes* linearly separable:\n",
        "\n",
        "$$x \\in \\mathbb{R}^d \\xrightarrow{\\Phi} \\Phi(x) \\in \\mathbb{R}^D$$\n",
        "\n",
        "where $D \\gg d$ (many more dimensions).\n",
        "\n",
        "### The Kernel Trick\n",
        "Computing $\\Phi(x)$ explicitly can be expensive. The **kernel trick** lets us compute similarity in the high-dimensional space *without* ever computing $\\Phi$ directly:\n",
        "\n",
        "$$K(x, y) = \\langle \\Phi(x), \\Phi(y) \\rangle$$\n",
        "\n",
        "This inner product is all we need for algorithms like SVM!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's visualize the concentric circles problem\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_circles\n",
        "\n",
        "# Generate concentric circles\n",
        "X, y = make_circles(n_samples=100, factor=0.5, noise=0.05, random_state=42)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X[y==0, 0], X[y==0, 1], c='blue', label='Class 0', s=50)\n",
        "plt.scatter(X[y==1, 0], X[y==1, 1], c='red', label='Class 1', s=50)\n",
        "plt.title('Concentric Circles: NOT Linearly Separable', fontsize=14)\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.axis('equal')\n",
        "plt.show()\n",
        "\n",
        "print(\"â“ Can you draw a single straight line to separate blue from red?\")\n",
        "print(\"   Answer: No! That's why we need kernel methods.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. The RBF (Radial Basis Function) Kernel\n",
        "\n",
        "The most popular classical kernel is the **RBF kernel** (also called Gaussian kernel):\n",
        "\n",
        "$$K_{RBF}(x, y) = \\exp\\left(-\\gamma \\|x - y\\|^2\\right)$$\n",
        "\n",
        "### Key Properties:\n",
        "- **Distance-based**: Similarity depends on Euclidean distance\n",
        "- **Local**: Nearby points have high similarity, distant points have low similarity\n",
        "- **Smooth decay**: Similarity decreases smoothly with distance\n",
        "\n",
        "### The Î³ (gamma) parameter:\n",
        "- Small Î³ â†’ Wide kernel, more points considered \"similar\"\n",
        "- Large Î³ â†’ Narrow kernel, only very close points are similar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "\n",
        "# Compute RBF kernel on our circles data\n",
        "K_rbf = rbf_kernel(X, gamma=1.0)\n",
        "\n",
        "# Visualize the kernel matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(K_rbf, cmap='viridis')\n",
        "plt.colorbar(label='Similarity')\n",
        "plt.title('RBF Kernel Matrix\\n(Diagonal = self-similarity = 1.0)', fontsize=14)\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Sample Index')\n",
        "plt.show()\n",
        "\n",
        "print(\"ðŸ” Notice the diagonal blur pattern.\")\n",
        "print(\"   This is because RBF is 'myopic' - it only sees local neighborhoods.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Quantum Kernels: A Different Geometry\n",
        "\n",
        "### The Quantum Approach\n",
        "Instead of mapping to $\\mathbb{R}^D$, quantum kernels map data to **Hilbert space** using quantum circuits:\n",
        "\n",
        "$$x \\xrightarrow{U(x)} |\\Phi(x)\\rangle \\in \\mathbb{C}^{2^n}$$\n",
        "\n",
        "Where:\n",
        "- $U(x)$ is a parameterized quantum circuit\n",
        "- $n$ is the number of qubits\n",
        "- $2^n$ is the Hilbert space dimension (exponentially large!)\n",
        "\n",
        "### Quantum Kernel (Fidelity)\n",
        "The quantum kernel measures the **overlap** between quantum states:\n",
        "\n",
        "$$K_Q(x, y) = |\\langle \\Phi(x) | \\Phi(y) \\rangle|^2$$\n",
        "\n",
        "### The Key Difference: ENTANGLEMENT\n",
        "- Classical: Each feature is processed independently\n",
        "- Quantum: Entanglement creates **correlations** between features\n",
        "\n",
        "This allows quantum kernels to capture patterns invisible to classical methods!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's visualize a quantum feature map circuit\n",
        "from qiskit.circuit.library import ZZFeatureMap\n",
        "\n",
        "# Create a 2-qubit ZZFeatureMap\n",
        "feature_map = ZZFeatureMap(feature_dimension=2, reps=1, entanglement='linear')\n",
        "\n",
        "print(\"ðŸ”® ZZ Feature Map Circuit (2 qubits):\")\n",
        "print(\"=\"*50)\n",
        "print(feature_map.decompose())\n",
        "print(\"\\nðŸ“Œ Key elements:\")\n",
        "print(\"   - H gates: Create superposition\")\n",
        "print(\"   - P gates: Encode data as rotation angles\")\n",
        "print(\"   - CX gates: Create ENTANGLEMENT between qubits\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Why Eigenvalues Measure Expressivity\n",
        "\n",
        "### Eigenvalue Decomposition\n",
        "Every kernel matrix $K$ can be decomposed as:\n",
        "\n",
        "$$K = V \\Lambda V^T$$\n",
        "\n",
        "Where:\n",
        "- $V$ = eigenvectors (directions in feature space)\n",
        "- $\\Lambda$ = eigenvalues $\\lambda_1 \\geq \\lambda_2 \\geq ... \\geq \\lambda_n \\geq 0$\n",
        "\n",
        "### What Eigenvalues Tell Us\n",
        "The **eigenvalue spectrum** reveals the \"effective dimensionality\":\n",
        "\n",
        "| Pattern | Meaning |\n",
        "|:--------|:--------|\n",
        "| Fast decay (Î» â†’ 0 quickly) | Low rank, compressed representation |\n",
        "| Slow decay (Î» stays high) | High rank, expressive representation |\n",
        "\n",
        "### The Quantum Advantage\n",
        "If quantum eigenvalues decay slower than classical, the quantum kernel accesses **more dimensions** of the feature space â€” higher expressivity!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize eigenvalue decay\n",
        "eigenvalues = np.linalg.eigvalsh(K_rbf)[::-1]  # Sort descending\n",
        "eigenvalues = eigenvalues / eigenvalues[0]     # Normalize\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.semilogy(eigenvalues, 'o-', color='purple')\n",
        "plt.axhline(y=0.01, color='red', linestyle='--', label='1% threshold')\n",
        "plt.fill_between(range(len(eigenvalues)), eigenvalues, 0.01, \n",
        "                 where=eigenvalues > 0.01, alpha=0.3, color='purple')\n",
        "plt.title('Eigenvalue Spectrum of RBF Kernel', fontsize=14)\n",
        "plt.xlabel('Component Index')\n",
        "plt.ylabel('Eigenvalue (log scale)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.5)\n",
        "plt.show()\n",
        "\n",
        "effective_rank = np.sum(eigenvalues > 0.01)\n",
        "print(f\"ðŸ“Š Effective Rank (Î» > 1%): {effective_rank} out of {len(eigenvalues)}\")\n",
        "print(f\"   This means DaRBF kernel uses {effective_rank} significant dimensions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Key Takeaways\n",
        "\n",
        "| Concept | Classical (RBF) | Quantum (Fidelity) |\n",
        "|:--------|:----------------|:-------------------|\n",
        "| **Similarity Measure** | Euclidean distance | Hilbert space overlap |\n",
        "| **Geometry** | Local (myopic) | Non-local (interference) |\n",
        "| **Feature Space** | Infinite-dim RKHS | $2^n$ dimensional |\n",
        "| **Correlations** | None | Entanglement-induced |\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸš€ Next Steps\n",
        "\n",
        "Now that you understand the theory, explore the experiments:\n",
        "\n",
        "1. **Notebook 02**: Visual comparison of kernel heatmaps (\"Fog vs Crystal\")\n",
        "2. **Notebook 03**: Eigenvalue analysis proving expressivity differences\n",
        "3. **Notebook 04**: Scaling experiment showing \"Rank Explosion\" at 8 qubits\n",
        "\n",
        "Happy exploring! ðŸ”¬"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
